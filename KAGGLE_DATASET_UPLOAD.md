# ğŸ”§ Kaggle Training - Dataset Upload Method

## âš ï¸ Váº¥n Äá»: Kaggle KhÃ´ng CÃ³ Internet

Kaggle notebooks **KHÃ”NG thá»ƒ** clone tá»« GitHub vÃ¬ khÃ´ng cÃ³ internet access.

**Giáº£i phÃ¡p**: Upload code nhÆ° Kaggle Dataset!

---

## ğŸ“¦ PhÆ°Æ¡ng PhÃ¡p 1: Upload Dataset (Khuyáº¿n nghá»‹)

### BÆ°á»›c 1: Download Repo vá» MÃ¡y

```powershell
# Windows - PowerShell
cd C:\Users\d0ngle8k\Desktop

# Download tá»« GitHub
git pull origin main

# Hoáº·c download ZIP tá»« GitHub:
# https://github.com/d0ngle8k/NLP-Processing/archive/refs/heads/main.zip
```

### BÆ°á»›c 2: Táº¡o ZIP File

```powershell
# Zip thÆ° má»¥c (khÃ´ng cáº§n .git, .venv, build, dist)
cd "C:\Users\d0ngle8k\Desktop\New folder (2)\NLP-Processing"

# Táº¡o clean copy
mkdir temp_kaggle
Copy-Item -Path .\* -Destination .\temp_kaggle\ -Exclude .git,.venv,build,dist,__pycache__,*.pyc -Recurse

# Zip
Compress-Archive -Path .\temp_kaggle\* -DestinationPath .\nlp-processing-kaggle.zip

# Clean up
Remove-Item -Recurse -Force .\temp_kaggle
```

### BÆ°á»›c 3: Upload lÃªn Kaggle Dataset

1. **VÃ o Kaggle Datasets**: https://www.kaggle.com/datasets
2. **Click "New Dataset"** (gÃ³c trÃªn bÃªn pháº£i)
3. **Upload File**:
   - KÃ©o tháº£ `nlp-processing-kaggle.zip`
   - Hoáº·c click "Select Files" â†’ chá»n ZIP
4. **Äiá»n thÃ´ng tin**:
   - **Title**: `NLP Processing Code`
   - **Subtitle**: `PhoBERT Fine-tuning for Vietnamese Event Extraction`
   - **Description**: 
     ```
     Code and training data for PhoBERT fine-tuning.
     
     Includes:
     - Training scripts
     - PhoBERT trainer
     - 76K+ training samples
     - Pipeline code
     ```
   - **Visibility**: Private (hoáº·c Public náº¿u muá»‘n)
5. **Click "Create"**

â±ï¸ Upload time: ~2-5 phÃºt (tÃ¹y máº¡ng)

### BÆ°á»›c 4: Táº¡o Kaggle Notebook

1. **VÃ o**: https://www.kaggle.com/code
2. **Click "New Notebook"**
3. **Settings** â†’ **Accelerator** â†’ **GPU P100**
4. **Click "Add Data"** (bÃªn pháº£i):
   - Search: `nlp processing code` (dataset vá»«a upload)
   - Click **Add**

### BÆ°á»›c 5: Copy Code ra Working Directory

```python
# Cell 1: Setup
!ls -la /kaggle/input

# Cell 2: Extract code
!unzip /kaggle/input/nlp-processing-code/nlp-processing-kaggle.zip -d /kaggle/working/
%cd /kaggle/working

# Cell 3: Verify
!ls -la
!ls training_data/
```

### BÆ°á»›c 6: Install Dependencies

```python
# Cell 4: Install
!pip install -q torch transformers underthesea tqdm
```

### BÆ°á»›c 7: Check GPU

```python
# Cell 5: Check GPU
import torch
print(f"GPU: {torch.cuda.get_device_name(0)}")
print(f"CUDA: {torch.cuda.is_available()}")
```

### BÆ°á»›c 8: Start Training

```python
# Cell 6: Train (20-30 phÃºt)
!python train_phobert.py --epochs 3 --batch_size 16
```

### BÆ°á»›c 9: Download Model

```python
# Cell 7: Create ZIP
!zip -r phobert_finetuned.zip models/phobert_finetuned/

# Cell 8: Check size
!ls -lh phobert_finetuned.zip

# Download tá»« Output panel â†’
```

---

## ğŸ“¦ PhÆ°Æ¡ng PhÃ¡p 2: Copy-Paste Code (Alternative)

Náº¿u khÃ´ng muá»‘n upload dataset, copy-paste code trá»±c tiáº¿p:

### Cell 1: Create Directory Structure
```python
!mkdir -p core_nlp services database scripts training_data
```

### Cell 2: Paste train_phobert.py
```python
%%writefile train_phobert.py
# Copy toÃ n bá»™ ná»™i dung tá»« train_phobert.py
# Paste vÃ o Ä‘Ã¢y...
```

### Cell 3: Paste phobert_trainer.py
```python
%%writefile core_nlp/phobert_trainer.py
# Copy toÃ n bá»™ ná»™i dung...
```

**âŒ NhÆ°á»£c Ä‘iá»ƒm**: Pháº£i paste nhiá»u files (10+ files), dá»… lá»—i

---

## ğŸ¯ So SÃ¡nh PhÆ°Æ¡ng PhÃ¡p

| Method | Pros | Cons | Time |
|--------|------|------|------|
| **Upload Dataset** | âœ… Dá»…, nhanh, Ã­t lá»—i | Cáº§n upload láº§n Ä‘áº§u | 5-10 phÃºt |
| Copy-Paste Code | KhÃ´ng cáº§n upload | âŒ Nhiá»u lá»—i, máº¥t thá»i gian | 20-30 phÃºt |

**Khuyáº¿n nghá»‹: Upload Dataset** ğŸ†

---

## ğŸ“ Template Kaggle Notebook (Sau Upload Dataset)

```python
# ==================== CELL 1: Extract Code ====================
!ls /kaggle/input
!unzip /kaggle/input/nlp-processing-code/*.zip -d /kaggle/working/
%cd /kaggle/working
!ls -la

# ==================== CELL 2: Install ====================
!pip install -q torch transformers underthesea tqdm

# ==================== CELL 3: Check GPU ====================
import torch
print(f"GPU: {torch.cuda.get_device_name(0)}")
print(f"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

# ==================== CELL 4: Check Data ====================
!ls training_data/
import json
with open('training_data/phobert_training_augmented.json') as f:
    data = json.load(f)
print(f"Samples: {len(data):,}")

# ==================== CELL 5: Train (25 min) ====================
!python train_phobert.py --epochs 3 --batch_size 16

# ==================== CELL 6: Create ZIP ====================
!zip -r phobert_finetuned.zip models/phobert_finetuned/
!ls -lh phobert_finetuned.zip

# Download tá»« Output panel â†’
```

---

## âœ… Quick Checklist

### Before Starting:
- [ ] ÄÃ£ download repo vá» mÃ¡y
- [ ] ÄÃ£ táº¡o ZIP file (clean, no .git/.venv)
- [ ] ÄÃ£ upload lÃªn Kaggle Dataset
- [ ] ÄÃ£ verify phone number

### In Kaggle:
- [ ] ÄÃ£ táº¡o notebook má»›i
- [ ] ÄÃ£ báº­t GPU P100/T4
- [ ] ÄÃ£ add dataset vÃ o notebook
- [ ] ÄÃ£ extract code ra /kaggle/working
- [ ] ÄÃ£ install dependencies
- [ ] GPU confirmed working
- [ ] Training data verified
- [ ] Training started

### After Training:
- [ ] Training completed (3/3 epochs)
- [ ] ÄÃ£ táº¡o ZIP file
- [ ] ÄÃ£ download vá» local
- [ ] ÄÃ£ test model
- [ ] ÄÃ£ commit lÃªn GitHub

---

## ğŸ†˜ Troubleshooting

### "Could not resolve host: github.com"
â†’ **ÄÃºng rá»“i!** Kaggle khÃ´ng cÃ³ internet. DÃ¹ng Dataset upload method.

### "No such file or directory"
â†’ Check dataset Ä‘Ã£ add vÃ o notebook chÆ°a: Click "Add Data" â†’ Search dataset

### "Cannot unzip"
â†’ Check path: `!ls /kaggle/input/` Ä‘á»ƒ xem Ä‘Ãºng tÃªn dataset

### Dataset upload failed
â†’ File quÃ¡ lá»›n? XÃ³a thÆ° má»¥c khÃ´ng cáº§n: .git, .venv, build, dist, __pycache__

---

## ğŸ Files to Prepare

### Essential (Pháº£i cÃ³):
```
âœ… train_phobert.py
âœ… core_nlp/phobert_trainer.py
âœ… core_nlp/phobert_model.py
âœ… core_nlp/pipeline.py
âœ… core_nlp/time_parser.py
âœ… training_data/phobert_training_augmented.json
```

### Optional (CÃ³ thá»ƒ bá»):
```
âŒ .git/
âŒ .venv/
âŒ build/
âŒ dist/
âŒ __pycache__/
âŒ *.pyc
âŒ version_document/
âŒ tests/*.json (trá»« test_cases.json náº¿u cáº§n)
```

---

## ğŸš€ Final Steps

1. âœ… Upload dataset lÃªn Kaggle
2. âœ… Táº¡o notebook + báº­t GPU
3. âœ… Add dataset vÃ o notebook
4. âœ… Extract + install
5. âœ… Train (25 phÃºt)
6. âœ… Download model
7. âœ… Test local + commit

**Total time**: ~35-40 phÃºt (setup 10' + training 25')

**Cost**: FREE

**Result**: PhoBERT fine-tuned model! ğŸ‰
